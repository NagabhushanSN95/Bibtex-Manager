% Generated by Bibtex Manager on 30/12/2021 05:34:08 PM
% Configs: journal.json

% Wilcoxon Signed Rank Test
@article{wilcoxon1945individual,
    title = {Individual Comparisons by Ranking Methods,},
    author = {Wilcoxon, Frank},
    volume = {1},
    number = {6},
    pages = {80--83},
    year = {1945}
}

@article{legge1980contrast,
    title = {Contrast masking in human vision},
    author = {Legge, Gordon E and Foley, John M},
    journal = {J. Opt. Soc. Am.},
    volume = {70},
    number = {12},
    pages = {1458--1471},
    year = {1980}
}

@article{rao1999predictive,
    title = {Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects},
    author = {Rao, Rajesh PN and Ballard, Dana H},
    journal = {Nature neuroscience},
    volume = {2},
    number = {1},
    pages = {79--87},
    year = {1999}
}

% Surface Splatting
@inproceedings{zwicker2001splatting,
    title = {Surface Splatting},
    author = {Zwicker, Matthias and Pfister, Hanspeter and Van Baar, Jeroen and Gross, Markus},
    booktitle = {ACM Comp. Graph. Int. Tech. (CGIT)},
    year = {2001}
}

% Casella Berger book
@book{casella2002statistical,
    title = {Statistical Inference},
    author = {Casella, George and Berger, Roger L},
    volume = {2},
    year = {2002}
}

% ITU-R Recommendation BT 500.11
@techreport{itu2002methodology,
    title = {Methodology for the subjective assessment of the quality of television pictures {ITU-R Recommendation BT.500-11}},
    institution = {Int. Telecommun. Union},
    year = {2002}
}

% MS-SSIM
@inproceedings{wang2003multiscale,
    title = {Multiscale structural similarity for image quality assessment},
    author = {Wang, Zhou and Simoncelli, Eero P and Bovik, Alan C},
    booktitle = {Asilomar Conf. Signals, Syst. Comput.},
    year = {2003}
}

@article{wiegand2003overview,
    title = {Overview of the H.264/AVC video coding standard},
    author = {Wiegand, Thomas and Sullivan, Gary J and Bjontegaard, Gisle and Luthra, Ajay},
    journal = {IEEE Trans. Circuits Syst. Video Technol.},
    volume = {13},
    number = {7},
    pages = {560-576},
    year = {2003}
}

% Criminisi et. al.
@article{criminisi2004region,
    title = {Region Filling and Object Removal by Exemplar-Based Image Inpainting},
    author = {Criminisi, Antonio and P{\'e}rez, Patrick and Toyama, Kentaro},
    journal = {IEEE Trans. Image Process.},
    volume = {13},
    number = {9},
    pages = {1200-1212},
    year = {2004}
}

% KTH
@inproceedings{schuldt2004recognizing,
    title = {Recognizing human actions: a local {SVM} approach},
    author = {Schuldt, Christian and Laptev, Ivan and Caputo, Barbara},
    booktitle = {Int. Conf. Pattern Recog. (ICPR)},
    year = {2004}
}

% SSIM
@article{wang2004image,
    title = {Image quality assessment: from error visibility to structural similarity},
    author = {Wang, Zhou and Bovik, Alan C and Sheikh, Hamid R and Simoncelli, Eero P},
    journal = {IEEE Trans. Image Process.},
    volume = {13},
    number = {4},
    pages = {600--612},
    year = {2004}
}

@article{ren2005data,
    title = {A Data-Driven Approach to Quantifying Natural Human Motion},
    author = {Ren, Liu and Patrick, Alton and Efros, Alexei A and Hodgins, Jessica K and Rehg, James M},
    journal = {ACM Trans. Graph.},
    volume = {24},
    number = {3},
    pages = {1090--1097},
    year = {2005}
}

% Distance Correlation
@article{szekely2007measuring,
    title = {Measuring and testing dependence by correlation of distances},
    author = {Sz\'ekely, G\'abor J and Rizzo, Maria L and Bakirov, Nail K},
    journal = {Ann. Statist.},
    volume = {35},
    number = {6},
    pages = {2769--2794},
    year = {2007}
}

@article{wexler2007space,
    title = {Space-Time Completion of Video},
    author = {Wexler, Yonatan and Shechtman, Eli and Irani, Michal},
    journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
    volume = {29},
    number = {3},
    pages = {463-476},
    year = {2007}
}

% Patch Match
@article{barnes2009patchmatch,
    title = {PatchMatch: A Randomized Correspondence Algorithm for Structural Image Editing},
    author = {Barnes, Connelly and Shechtman, Eli and Finkelstein, Adam and Goldman, Dan B},
    journal = {ACM Trans. Graph.},
    volume = {28},
    number = {3},
    pages = {24},
    year = {2009}
}

% MOVIE
@article{seshadrinathan2009motion,
    title = {Motion tuned spatio-temporal quality assessment of natural videos},
    author = {Seshadrinathan, Kalpana and Bovik, Alan C},
    journal = {IEEE Trans. Image Process.},
    volume = {19},
    number = {2},
    pages = {335--350},
    year = {2009}
}

@inproceedings{de2010h,
    title = {{A H.264/AVC} video database for the evaluation of quality metrics},
    author = {De Simone, Francesca and Tagliasacchi, Marco and Naccari, Matteo and Tubaro, Stefano and Ebrahimi, Touradj},
    booktitle = {IEEE Int. Conf. Acoust. Speech Signal Process. (ICASSP)},
    year = {2010}
}

% LIVE-VQA
@article{seshadrinathan2010study,
    title = {Study of subjective and objective quality assessment of video},
    author = {Seshadrinathan, Kalpana and Soundararajan, Rajiv and Bovik, Alan C and Cormack, Lawrence K},
    journal = {IEEE Trans. Image Process.},
    volume = {19},
    number = {6},
    pages = {1427--1441},
    year = {2010}
}

@inproceedings{seshadrinathan2010subjective,
    title = {A subjective study to evaluate video quality assessment algorithms},
    author = {Seshadrinathan, Kalpana and Soundararajan, Rajiv and Bovik, Alan C and Cormack, Lawrence K},
    booktitle = {SPIE Human Vis. Electron. Imag.},
    year = {2010}
}

% Middlebury Optical Flow Database
@article{baker2011middlebury,
    title = {A database and evaluation methodology for optical flow},
    author = {Baker, Simon and Scharstein, Daniel and Lewis, JP and Roth, Stefan and Black, Michael J and Szeliski, Richard},
    journal = {Int. J. Comput. Vis.},
    volume = {92},
    number = {1},
    pages = {1--31},
    year = {2011}
}

% Caltech Pedestrian
@article{dollar2011pedestrian,
    title = {Pedestrian detection: An evaluation of the state of the art},
    author = {Doll\'ar, Piotr and Wojek, Christian and Schiele, Bernt and Perona, Pietro},
    journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
    volume = {34},
    number = {4},
    pages = {743--761},
    year = {2011}
}

% ST-MAD
@inproceedings{vu2011spatiotemporal,
    title = {A spatiotemporal most-apparent-distortion model for video quality assessment},
    author = {Vu, Phong V and Vu, Cuong T and Chandler, Damon M},
    booktitle = {IEEE Int. Conf. Image Process. (ICIP)},
    year = {2011}
}

% MPI Sintel
@inproceedings{butler2012sintel,
    title = {A naturalistic open source movie for optical flow evaluation},
    author = {Butler, Daniel J and Wulff, Jonas and Stanley, Garrett B and Black, Michael J},
    booktitle = {Eur. Conf. Comput. Vis. (ECCV)},
    year = {2012}
}

@article{den2012prediction,
    title = {How prediction errors shape perception, attention, and motivation},
    author = {Den Ouden, Hanneke EM and Kok, Peter and De Lange, Floris P},
    journal = {Frontiers in psychology},
    volume = {3},
    pages = {548},
    year = {2012}
}

% TU-Berlin Sketch Dataset
@article{eitz2012humans,
    title = {How Do Humans Sketch Objects?},
    author = {Eitz, Mathias and Hays, James and Alexa, Marc},
    journal = {ACM Trans. Graph.},
    volume = {31},
    number = {4},
    pages = {1--10},
    year = {2012}
}

% BRISQUE
@article{mittal2012no,
    title = {No-reference image quality assessment in the spatial domain},
    author = {Mittal, Anish and Moorthy, Anush Krishna and Bovik, Alan C},
    journal = {IEEE Trans. Image Process.},
    volume = {21},
    number = {12},
    pages = {4695--4708},
    year = {2012}
}

% UCF-101
@article{soomro2012ucf101,
    title = {UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild},
    author = {Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
    journal = {arXiv e-prints},
    eid = {arXiv:1212.0402},
    pages = {arXiv:1212.0402},
    archivePrefix = {arXiv},
    eprint = {1212.0402},
    year = {2012}
}

% KITTI
@article{geiger2013vision,
    title = {Vision meets robotics: The {KITTI} dataset},
    author = {Geiger, Andreas and Lenz, Philip and Stiller, Christoph and Urtasun, Raquel},
    journal = {Int. J. Robot. Res.},
    volume = {32},
    number = {11},
    pages = {1231--1237},
    year = {2013}
}

% NIQE
@article{mittal2013making,
    title = {Making a ``Completely Blind" Image Quality Analyzer},
    author = {Mittal, Anish and Soundararajan, Rajiv and Bovik, Alan C},
    journal = {IEEE Sign. Process. Lett.},
    volume = {20},
    number = {3},
    pages = {209--212},
    year = {2013}
}

% ST-RRED
@article{soundararajan2013video,
    title = {Video Quality Assessment by Reduced Reference Spatio-Temporal Entropic Differencing},
    author = {Soundararajan, Rajiv and Bovik, Alan C},
    journal = {IEEE Trans. Circuits Syst. Video Technol.},
    volume = {23},
    number = {4},
    pages = {684--694},
    year = {2013}
}

% PENN
@inproceedings{zhang2013actemes,
    title = {From Actemes to Action: A Strongly-supervised Representation for Detailed Action Understanding},
    author = {Zhang, Weiyu and Zhu, Menglong and Derpanis, Konstantinos G},
    booktitle = {IEEE Int. Conf. Comput. Vis. (ICCV)},
    year = {2013}
}

% GAN
@inproceedings{goodfellow2014gan,
    title = {Generative Adversarial Nets},
    author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
    booktitle = {Adv. Neural Inf. Process. Syst. (NeurIPS)},
    year = {2014}
}

% Video BLIINDS
@article{saad2014blind,
    title = {Blind Prediction of Natural Video Quality},
    author = {Saad, Michele A and Bovik, Alan C and Charrier, Christophe},
    journal = {IEEE Trans. Image Process.},
    volume = {23},
    number = {3},
    pages = {1352--1365},
    year = {2014}
}

% Face Detection - Aggregate Channel Features
@inproceedings{yang2014aggregate,
    title = {Aggregate Channel Features for Multi-view Face Detection},
    author = {Yang, Bin and Yan, Junjie and Lei, Zhen and Li, Stan Z},
    booktitle = {IEEE International Joint Conference on Biometrics},
    year = {2014}
}

@inproceedings{zeiler2014visualizing,
    title = {Visualizing and understanding convolutional networks},
    author = {Zeiler, Matthew D and Fergus, Rob},
    booktitle = {Eur. Conf. Comput. Vis. (ECCV)},
    year = {2014}
}

% Keras
@misc{chollet2015keras,
    title = {Keras},
    author = {Chollet, Fran\c{c}ois and others},
    howpublished = {\url{https://keras.io}},
    year = {2015}
}

% FLowNet
@inproceedings{dosovitskiy2015flownet,
    title = {FlowNet: Learning Optical Flow With Convolutional Networks},
    author = {Dosovitskiy, Alexey and Fischer, Philipp and Ilg, Eddy and Hausser, Philip and Hazirbas, Caner and Golkov, Vladimir and van der Smagt, Patrick and Cremers, Daniel and Brox, Thomas},
    booktitle = {IEEE Int. Conf. Comput. Vis. (ICCV)},
    year = {2015}
}

% STN
@inproceedings{jaderberg2015stn,
    title = {Spatial Transformer Networks},
    author = {Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and kavukcuoglu, koray},
    booktitle = {Adv. Neural Inf. Process. Syst. (NeurIPS)},
    year = {2015}
}

@misc{oculus2015atw_examined,
    title = {Asynchronous Timewarp Examined},
    author = {Antonov, Michael},
    journal = {Oculus Developer Blogs},
    howpublished = {\url{https://developer.oculus.com/blog/asynchronous-timewarp-examined}},
    note = {Accessed: 24-June-2021},
    year = {2015}
}

% Epic Flow
@inproceedings{revaud2015epicflow,
    title = {{EpicFlow} : Edge-Preserving Interpolation of Correspondences for Optical Flow},
    author = {Revaud, Jerome and Weinzaepfel, Philippe and Harchaoui, Zaid and Schmid, Cordelia},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2015}
}

% U-Net
@inproceedings{ronneberger2015unet,
    title = {{U-Net}: Convolutional Networks for Biomedical Image Segmentation},
    author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
    booktitle = {International Conference on Medical Image Computing and Computer-Assisted Intervention},
    year = {2015}
}

% ImageNet
@article{russakovsky2015imagenet,
    title = {{ImageNet} Large Scale Visual Recognition Challenge},
    author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C and Fei-Fei, Li},
    journal = {Int. J. Comput. Vis.},
    volume = {115},
    number = {3},
    pages = {211--252},
    year = {2015}
}

% VGG Net
@inproceedings{simonyan2015very,
    title = {Very deep convolutional networks for large-scale image recognition},
    author = {Simonyan, Karen and Zisserman, Andrew},
    booktitle = {Int. Conf. Learn. Represent. (ICLR)},
    year = {2015}
}

@inproceedings{srivastava2015unsupervised,
    title = {Unsupervised Learning of Video Representations using {LSTMs}},
    author = {Srivastava, Nitish and Mansimov, Elman and Salakhudinov, Ruslan},
    booktitle = {Int. Conf. Mach. Learn. (ICML)},
    year = {2015}
}

% Inception
@inproceedings{szegedy2015going,
    title = {Going Deeper With Convolutions},
    author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2015}
}

% C3D
@inproceedings{tran2015learning,
    title = {Learning Spatiotemporal Features With 3D Convolutional Networks},
    author = {Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
    booktitle = {IEEE Int. Conf. Comput. Vis. (ICCV)},
    year = {2015}
}

@inproceedings{xingjian2015convolutional,
    title = {Convolutional {LSTM} Network: A Machine Learning Approach for Precipitation Nowcasting},
    author = {SHI, Xingjian and Chen, Zhourong and Wang, Hao and Yeung, Dit-Yan and Wong, Wai-Kin and Woo, Wang-chun},
    booktitle = {Adv. Neural Inf. Process. Syst. (NeurIPS)},
    year = {2015}
}

@inproceedings{agrawal2016learning,
    title = {Learning to Poke by Poking: Experiential Learning of Intuitive Physics},
    author = {Agrawal, Pulkit and Nair, Ashvin V and Abbeel, Pieter and Malik, Jitendra and Levine, Sergey},
    booktitle = {Adv. Neural Inf. Process. Syst. (NeurIPS)},
    year = {2016}
}

% PUSH Dataset
@inproceedings{finn2016unsupervised,
    title = {Unsupervised Learning for Physical Interaction through Video Prediction},
    author = {Finn, Chelsea and Goodfellow, Ian and Levine, Sergey},
    booktitle = {Adv. Neural Inf. Process. Syst. (NeurIPS)},
    year = {2016}
}

% ResNet
@inproceedings{he2016deep,
    title = {Deep Residual Learning for Image Recognition},
    author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2016}
}

% SACONVA
@article{li2016no,
    title = {No-Reference Video Quality Assessment With 3D Shearlet Transform and Convolutional Neural Networks},
    author = {Li, Yuming and Po, Lai-Man and Cheung, Chun-Ho and Xu, Xuyuan and Feng, Litong and Yuan, Fang and Cheung, Kwok-Wai},
    journal = {IEEE Trans. Circuits Syst. Video Technol.},
    volume = {26},
    number = {6},
    pages = {1044--1057},
    year = {2016}
}

@inproceedings{luo2016hole,
    title = {A Hole Filling Approach Based on Background Reconstruction for View Synthesis in 3D Video},
    author = {Luo, Guibo and Zhu, Yuesheng and Li, Zhaotian and Zhang, Liming},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2016}
}

% Beyond MSE
@inproceedings{mathieu2016deep,
    title = {Deep multi-scale video prediction beyond mean square error},
    author = {Mathieu, Michael and Couprie, Camille and LeCun, Yann},
    booktitle = {Int. Conf. Learn. Represent. (ICLR)},
    year = {2016}
}

% VIIDEO
@article{mittal2016completely,
    title = {A Completely Blind Video Integrity Oracle},
    author = {Mittal, Anish and Saad, Michele A and Bovik, Alan C},
    journal = {IEEE Trans. Image Process.},
    volume = {25},
    number = {1},
    pages = {289--300},
    year = {2016}
}

% MSR Action Dataset
@misc{msr2016action,
    title = {{MSR} Action Dataset},
    author = {{Microsoft Research}},
    howpublished = {\url{https://www.microsoft.com/en-us/download/details.aspx?id=52315}},
    year = {2016}
}

@misc{oculus2016asw,
    title = {Asynchronous Spacewarp},
    author = {Beeler, Dean},
    journal = {Oculus Developer Blogs},
    howpublished = {\url{https://developer.oculus.com/blog/asynchronous-spacewarp}},
    note = {Accessed: 24-June-2021},
    year = {2016}
}

@misc{oculus2016atw,
    title = {Asynchronous Timewarp on Oculus Rift},
    author = {Beeler, Dean and Gosalia, Anuj},
    journal = {Oculus Developer Blogs},
    howpublished = {\url{https://developer.oculus.com/blog/asynchronous-timewarp-on-oculus-rift}},
    note = {Accessed: 24-June-2021},
    year = {2016}
}

% Context Encoder
@inproceedings{pathak2016context,
    title = {Context Encoders: Feature Learning by Inpainting},
    author = {Pathak, Deepak and Krahenbuhl, Philipp and Donahue, Jeff and Darrell, Trevor and Efros, Alexei A.},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2016}
}

% Inception Score
@inproceedings{salimans2016improved,
    title = {Improved Techniques for Training {GANs}},
    author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
    booktitle = {Adv. Neural Inf. Process. Syst. (NeurIPS)},
    year = {2016}
}

% Inception v3
@inproceedings{szegedy2016rethinking,
    title = {Rethinking the Inception Architecture for Computer Vision},
    author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2016}
}

% Interleaved Reprojection
@misc{valve2016interleaved,
    title = {Interleaved Reprojection now enabled for all applications by default},
    author = {Leiby, Aaron},
    journal = {Steam Community},
    howpublished = {\url{https://steamcommunity.com/app/358720/discussions/0/385429254937377076/}},
    note = {Accessed: 12-October-2021},
    year = {2016}
}

@inproceedings{yu2016back,
    title = {Back to Basics: Unsupervised Learning of Optical Flow via Brightness Constancy and Motion Smoothness},
    author = {Yu, Jason J. and Harley, Adam W. and Derpanis, Konstantinos G.},
    booktitle = {Eur. Conf. Comput. Vis. (ECCV) Worksh.},
    year = {2016}
}

% Appearance Flow
@inproceedings{zhou2016view,
    title = {View Synthesis by Appearance Flow},
    author = {Zhou, Tinghui and Tulsiani, Shubham and Sun, Weilun and Malik, Jitendra and Efros, Alexei A},
    booktitle = {Eur. Conf. Comput. Vis. (ECCV)},
    year = {2016}
}

@article{cho2017hole,
    title = {Hole Filling Method for Depth Image Based Rendering Based on Boundary Decision},
    author = {Cho, Jea-Hyung and Song, Wonseok and Choi, Hyuk and Kim, Taejeong},
    journal = {IEEE Sign. Process. Lett.},
    volume = {24},
    number = {3},
    pages = {329-333},
    year = {2017}
}

% BAIR
@inproceedings{ebert2017self,
    title = {Self-Supervised Visual Planning with Temporal Skip Connections},
    author = {Ebert, Frederik and Finn, Chelsea and Lee, Alex X and Levine, Sergey},
    booktitle = {Conf. Robot Learn. (CoRL)},
    year = {2017}
}

% Image Visual Realism
@article{fan2017image,
    title = {Image Visual Realism: From Human Perception to Machine Computation},
    author = {Fan, Shaojing and Ng, Tian-Tsong and Koenig, Bryan Lee and Herberg, Jonathan Samuel and Jiang, Ming and Shen, Zhiqi and Zhao, Qi},
    journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
    volume = {40},
    number = {9},
    pages = {2180--2193},
    year = {2017}
}

@inproceedings{hosu2017konstanz,
    title = {The {Konstanz} natural video database {(KoNViD-1k)}},
    author = {Hosu, Vlad and Hahn, Franz and Jenadeleh, Mohsen and Lin, Hanhe and Men, Hui and Szir\'anyi, Tam\'as and Li, Shujun and Saupe, Dietmar},
    booktitle = {Int. Conf. Qual. Multimedia Exper. (QoMEX)},
    year = {2017}
}

% Locally Globally
@article{iizuka2017globally,
    title = {Globally and Locally Consistent Image Completion},
    author = {Iizuka, Satoshi and Simo-Serra, Edgar and Ishikawa, Hiroshi},
    journal = {ACM Trans. Graph.},
    volume = {36},
    number = {4},
    year = {2017}
}

% FlowNet2
@inproceedings{ilg2017flownet2,
    title = {FlowNet 2.0: Evolution of Optical Flow Estimation With Deep Networks},
    author = {Ilg, Eddy and Mayer, Nikolaus and Saikia, Tonmoy and Keuper, Margret and Dosovitskiy, Alexey and Brox, Thomas},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2017}
}

% CNN-IQA-Survey
@article{kim2017deep,
    title = {Deep Convolutional Neural Models for Picture-Quality Prediction: Challenges and Solutions to Data-Driven Image Quality Assessment},
    author = {Kim, Jongyoo and Zeng, Hui and Ghadiyaram, Deepti and Lee, Sanghoon and Zhang, Lei and Bovik, Alan C},
    journal = {IEEE Sign. Process. Mag.},
    volume = {34},
    number = {6},
    pages = {130--141},
    year = {2017}
}

% SR-GAN
@inproceedings{ledig2017photo,
    title = {Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network},
    author = {Ledig, Christian and Theis, Lucas and Husz\'ar, Ferenc and Caballero, Jose and Cunningham, Andrew and Acosta, Alejandro and Aitken, Andrew and Tejani, Alykhan and Totz, Johannes and Wang, Zehan and Shi, Wenzhe},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2017}
}

% Dual-Motion-GAN
@inproceedings{liang2017dual,
    title = {Dual Motion {GAN} for Future-Flow Embedded Video Prediction},
    author = {Liang, Xiaodan and Lee, Lisa and Dai, Wei and Xing, Eric P},
    booktitle = {IEEE Int. Conf. Comput. Vis. (ICCV)},
    year = {2017}
}

% PredNet
@inproceedings{lotter2017deep,
    title = {Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning},
    author = {Lotter, William and Kreiman, Gabriel and Cox, David},
    booktitle = {Int. Conf. Learn. Represent. (ICLR)},
    year = {2017}
}

% Soft 3D Reconstruction
@article{penner2017soft3d,
    title = {Soft {3D} Reconstruction for View Synthesis},
    author = {Penner, Eric and Zhang, Li},
    journal = {ACM Trans. Graph.},
    volume = {36},
    number = {6},
    year = {2017}
}

% SPyNet
@inproceedings{ranjan2017optical,
    title = {Optical Flow Estimation Using a Spatial Pyramid Network},
    author = {Ranjan, Anurag and Black, Michael J.},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2017}
}

@inproceedings{rezende2017malicious,
    title = {Malicious software classification using transfer learning of resnet-50 deep neural network},
    author = {Rezende, Edmar and Ruppert, Guilherme and Carvalho, Tiago and Ramos, Fabio and De Geus, Paulo},
    booktitle = {IEEE Int. Conf. Mach. Learn. App. (ICMLA)},
    year = {2017}
}

@inproceedings{villegas2017learning,
    title = {Learning to Generate Long-term Future via Hierarchical Prediction},
    author = {Ruben Villegas and Jimei Yang and Yuliang Zou and Sungryull Sohn and Xunyu Lin and Honglak Lee},
    booktitle = {Int. Conf. Mach. Learn. (ICML)},
    year = {2017}
}

% MCnet
@inproceedings{villegas2017mcnet,
    title = {Decomposing Motion and Content for Natural Video Sequence Prediction},
    author = {Villegas, Ruben and Yang, Jimei and Hong, Seunghoon and Lin, Xunyu and Lee, Honglak},
    booktitle = {Int. Conf. Learn. Represent. (ICLR)},
    year = {2017}
}

% VDA
@inproceedings{wu2017learning,
    title = {Learning to See Physics via Visual De-animation},
    author = {Wu, Jiajun and Lu, Erika and Kohli, Pushmeet and Freeman, Bill and Tenenbaum, Josh},
    booktitle = {Adv. Neural Inf. Process. Syst. (NeurIPS)},
    year = {2017}
}

% SFM Learner
@inproceedings{zhou2017unsupervised,
    title = {Unsupervised Learning of Depth and Ego-Motion From Video},
    author = {Zhou, Tinghui and Brown, Matthew and Snavely, Noah and Lowe, David G.},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2017}
}

% SV2P
@inproceedings{babaeizadeh2018stochastic,
    title = {Stochastic Variational Video Prediction},
    author = {Babaeizadeh, Mohammad and Finn, Chelsea and Erhan, Dumitru and Campbell, Roy H and Levine, Sergey},
    booktitle = {Int. Conf. Learn. Represent. (ICLR)},
    year = {2018}
}

@misc{burnes2018rtx,
    title = {{NVIDIA} {RTX} Technology: Making Real-Time Ray Tracing A Reality For Games - {NVIDIA} Blogs},
    author = {Burnes, Andrew},
    howpublished = {\url{https://www.nvidia.com/en-us/geforce/news/nvidia-rtx-real-time-game-ray-tracing/}},
    note = {Accessed: 12-June-2021},
    year = {2018}
}

@inproceedings{buslaev2018fully,
    title = {Fully Convolutional Network for Automatic Road Extraction From Satellite Imagery},
    author = {Buslaev, Alexander and Seferbekov, Selim and Iglovikov, Vladimir and Shvets, Alexey},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR) Worksh.},
    year = {2018}
}

% ContextVP
@inproceedings{byeon2018contextvp,
    title = {{ContextVP} : Fully Context-Aware Video Prediction},
    author = {Byeon, Wonmin and Wang, Qin and Kumar Srivastava, Rupesh and Koumoutsakos, Petros},
    booktitle = {Eur. Conf. Comput. Vis. (ECCV)},
    year = {2018}
}

@misc{caulfield2018difference,
    title = {What's the Difference Between Ray Tracing and Rasterization? - {NVIDIA} Blogs},
    author = {Caulfield, Brian},
    howpublished = {\url{https://blogs.nvidia.com/blog/2018/03/19/whats-difference-between-ray-tracing-rasterization}},
    note = {Accessed: 12-June-2021},
    year = {2018}
}

% SVG-LP
@inproceedings{denton2018stochastic,
    title = {Stochastic Video Generation with a Learned Prior},
    author = {Denton, Emily and Fergus, Rob},
    booktitle = {Int. Conf. Mach. Learn. (ICML)},
    year = {2018}
}

@inproceedings{he2018probabilistic,
    title = {Probabilistic Video Generation using Holistic Attribute Control},
    author = {He, Jiawei and Lehrmann, Andreas and Marino, Joseph and Mori, Greg and Sigal, Leonid},
    booktitle = {Eur. Conf. Comput. Vis. (ECCV)},
    year = {2018}
}

% LiteFlowNet
@inproceedings{hui2018liteflownet,
    title = {{LiteFlowNet}: A Lightweight Convolutional Neural Network for Optical Flow Estimation},
    author = {Hui, Tak-Wai and Tang, Xiaoou and Loy, Chen Change},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2018}
}

@inproceedings{janai2018unsupervised,
    title = {Unsupervised Learning of Multi-Frame Optical Flow with Occlusions},
    author = {Janai, Joel and Guney, Fatma and Ranjan, Anurag and Black, Michael and Geiger, Andreas},
    booktitle = {Eur. Conf. Comput. Vis. (ECCV)},
    year = {2018}
}

% O2P2
@inproceedings{janner2018reasoning,
    title = {Reasoning About Physical Interactions with Object-Centric Models},
    author = {Janner, Michael and Levine, Sergey and Freeman, William T and Tenenbaum, Joshua B and Finn, Chelsea and Wu, Jiajun},
    booktitle = {Int. Conf. Learn. Represent. (ICLR)},
    year = {2019}
}

% SAVP
@article{lee2018stochastic,
    title = {Stochastic Adversarial Video Prediction},
    author = {Lee, Alex X and Zhang, Richard and Ebert, Frederik and Abbeel, Pieter and Finn, Chelsea and Levine, Sergey},
    journal = {arXiv e-prints},
    eid = {arXiv:1804.01523},
    pages = {arXiv:1804.01523},
    archivePrefix = {arXiv},
    eprint = {1804.01523},
    year = {2018}
}

% VMAF
@article{li2018vmaf,
    title = {{VMAF} : The Journey Continues},
    author = {Li, Z and Bampis, C and Novak, J and Aaron, A and Swanson, K and Moorthy, A and Cock, J},
    journal = {The NETFLIX tech blog},
    year = {2018}
}

% DYAN
@inproceedings{liu2018dyan,
    title = {{DYAN} : A Dynamical Atoms-Based Network For Video Prediction},
    author = {Liu, Wenqian and Sharma, Abhishek and Camps, Octavia and Sznaier, Mario},
    booktitle = {Eur. Conf. Comput. Vis. (ECCV)},
    year = {2018}
}

% Anamoly Detection
@inproceedings{liu2018future,
    title = {Future Frame Prediction for Anomaly Detection - A New Baseline},
    author = {Liu, Wen and Luo, Weixin and Lian, Dongze and Gao, Shenghua},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2018}
}

% Partial Convolution
@inproceedings{liu2018pconv,
    title = {Image Inpainting for Irregular Holes Using Partial Convolutions},
    author = {Liu, Guilin and Reda, Fitsum A. and Shih, Kevin J. and Wang, Ting-Chun and Tao, Andrew and Catanzaro, Bryan},
    booktitle = {Eur. Conf. Comput. Vis. (ECCV)},
    year = {2018}
}

% UnFlow
@inproceedings{meister2018unflow,
    title = {{UnFlow}: Unsupervised Learning of Optical Flow With a Bidirectional Census Loss},
    author = {Meister, Simon and Hur, Junhwa and Roth, Stefan},
    booktitle = {AAAI (AAAI)},
    year = {2018}
}

@inproceedings{mormont2018comparison,
    title = {Comparison of Deep Transfer Learning Strategies for Digital Pathology},
    author = {Mormont, Romain and Geurts, Pierre and Maree, Raphael},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR) Worksh.},
    year = {2018}
}

% HRN
@inproceedings{mrowca2018flexible,
    title = {Flexible neural representation for physics prediction},
    author = {Mrowca, Damian and Zhuang, Chengxu and Wang, Elias and Haber, Nick and Fei-Fei, Li F and Tenenbaum, Josh and Yamins, Daniel L},
    booktitle = {Adv. Neural Inf. Process. Syst. (NeurIPS)},
    year = {2018}
}

@inproceedings{nguyen2018deep,
    title = {Deep {CNNs} for microscopic image classification by exploiting transfer learning and feature concatenation},
    author = {Nguyen, Long D and Lin, Dongyun and Lin, Zhiping and Cao, Jiuwen},
    booktitle = {IEEE Int. Symp. Circuits Syst. (ISCAS)},
    year = {2018}
}

% PieApp
@inproceedings{prashnani2018pieapp,
    title = {{PieAPP}: Perceptual Image-Error Assessment Through Pairwise Preference},
    author = {Prashnani, Ekta and Cai, Hong and Mostofi, Yasamin and Sen, Pradeep},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2018}
}

% PWCNet
@inproceedings{sun2018pwcnet,
    title = {{PWC-Net}: {CNNs} for Optical Flow Using Pyramid, Warping, and Cost Volume},
    author = {Sun, Deqing and Yang, Xiaodong and Liu, Ming-Yu and Kautz, Jan},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2018}
}

% Tulsiani et. al.
@inproceedings{tulsiani2018layer,
    title = {Layer-structured 3D Scene Inference via View Synthesis},
    author = {Tulsiani, Shubham and Tucker, Richard and Snavely, Noah},
    booktitle = {Eur. Conf. Comput. Vis. (ECCV)},
    year = {2018}
}

% MoCoGAN
@inproceedings{tulyakov2018mocogan,
    title = {{MoCoGAN}: Decomposing Motion and Content for Video Generation},
    author = {Tulyakov, Sergey and Liu, Ming-Yu and Yang, Xiaodong and Kautz, Jan},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2018}
}

@inproceedings{wang2018eidetic,
    title = {Eidetic {3D} {LSTM}: A Model for Video Prediction and Beyond},
    author = {Wang, Yunbo and Jiang, Lu and Yang, Ming-Hsuan and Li, Li-Jia and Long, Mingsheng and Fei-Fei, Li},
    booktitle = {Int. Conf. Learn. Represent. (ICLR)},
    year = {2019}
}

@inproceedings{wang2018occlusion,
    title = {Occlusion Aware Unsupervised Learning of Optical Flow},
    author = {Wang, Yang and Yang, Yi and Yang, Zhenheng and Zhao, Liang and Wang, Peng and Xu, Wei},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2018}
}

@inproceedings{wichers2018hierarchical,
    title = {Hierarchical Long-Term Video Prediction without Supervision},
    author = {Wichers, Nevan and Villegas, Ruben and Erhan, Dumitru and Lee, Honglak},
    booktitle = {Int. Conf. Mach. Learn. (ICML)},
    year = {2018}
}

% VPSS
@inproceedings{xu2018video,
    title = {Video Prediction via Selective Sampling},
    author = {Xu, Jingwei and Ni, Bingbing and Yang, Xiaokang},
    booktitle = {Adv. Neural Inf. Process. Syst. (NeurIPS)},
    year = {2018}
}

% MVS-Net
@inproceedings{yao2018mvsnet,
    title = {{MVSNet}: Depth Inference for Unstructured Multi-view Stereo},
    author = {Yao, Yao and Luo, Zixin and Li, Shiwei and Fang, Tian and Quan, Long},
    booktitle = {Eur. Conf. Comput. Vis. (ECCV)},
    year = {2018}
}

% BDD100K
@article{yu2018bdd100k,
    title = {{BDD100K} : A Diverse Driving Video Database with Scalable Annotation Tooling},
    author = {Yu, Fisher and Xian, Wenqi and Chen, Yingying and Liu, Fangchen and Liao, Mike and Madhavan, Vashisht and Darrell, Trevor},
    journal = {arXiv e-prints},
    eid = {arXiv:1805.04687},
    pages = {arXiv:1805.04687},
    archivePrefix = {arXiv},
    eprint = {1805.04687},
    year = {2018}
}

% Unreasonable-Effectiveness
@inproceedings{zhang2018unreasonable,
    title = {The Unreasonable Effectiveness of Deep Features as a Perceptual Metric},
    author = {Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2018}
}

% StereoMag
@article{zhou2018stereomag,
    title = {Stereo Magnification: Learning View Synthesis Using Multiplane Images},
    author = {Zhou, Tinghui and Tucker, Richard and Flynn, John and Fyffe, Graham and Snavely, Noah},
    journal = {ACM Trans. Graph.},
    volume = {37},
    number = {4},
    year = {2018}
}

% Sketchy
@inproceedings{zou2018sketchy,
    title = {SketchyScene: Richly-Annotated Scene Sketches},
    author = {Zou, Changqing and Yu, Qian and Du, Ruofei and Mo, Haoran and Song, Yi-Zhe and Xiang, Tao and Gao, Chengying and Chen, Baoquan and Zhang, Hao},
    booktitle = {Eur. Conf. Comput. Vis. (ECCV)},
    year = {2018}
}

% FutureGAN
@article{aigner2019futuregan,
    title = {{FutureGAN} : Anticipating the Future Frames of Video Sequences using Spatio-Temporal 3d Convolutions in Progressively Growing {GANs}},
    author = {Aigner, Sandra and K\"orner, Marco},
    journal = {Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci.},
    year = {2019}
}

% DAIN
@inproceedings{bao2019dain,
    title = {Depth-Aware Video Frame Interpolation},
    author = {Bao, Wenbo and Lai, Wei-Sheng and Ma, Chao and Zhang, Xiaoyun and Gao, Zhiyong and Yang, Ming-Hsuan},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2019}
}

@article{bao2019memcnet,
    title = {MEMC-Net: Motion Estimation and Motion Compensation Driven Neural Network for Video Interpolation and Enhancement},
    author = {Bao, Wenbo and Lai, Wei-Sheng and Zhang, Xiaoyun and Gao, Zhiyong and Yang, Ming-Hsuan},
    journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
    volume = {43},
    number = {3},
    pages = {933-948},
    year = {2021}
}

% BagNets
@inproceedings{brendel2019approximating,
    title = {Approximating {CNNs} with Bag-of-local-Features models works surprisingly well on ImageNet},
    author = {Brendel, Wieland and Bethge, Matthias},
    booktitle = {Int. Conf. Learn. Represent. (ICLR)},
    year = {2019}
}

% Extreme View Synthesis
@inproceedings{choi2019extreme,
    title = {Extreme View Synthesis},
    author = {Choi, Inchang and Gallo, Orazio and Troccoli, Alejandro and Kim, Min H and Kautz, Jan},
    booktitle = {IEEE Int. Conf. Comput. Vis. (ICCV)},
    year = {2019}
}

% DPG
@inproceedings{gao2019disentangling,
    title = {Disentangling Propagation and Generation for Video Prediction},
    author = {Gao, Hang and Xu, Huazhe and Cai, Qi-Zhi and Wang, Ruth and Yu, Fisher and Darrell, Trevor},
    booktitle = {IEEE Int. Conf. Comput. Vis. (ICCV)},
    year = {2019}
}

@inproceedings{geirhos2019imagenet,
    title = {ImageNet-trained {CNNs} are biased towards texture; increasing shape bias improves accuracy and robustness},
    author = {Geirhos, Robert and Rubisch, Patricia and Michaelis, and Bethge, Matthias and Wichmann, Felix A and Brendel, Wieland},
    booktitle = {Int. Conf. Learn. Represent. (ICLR)},
    year = {2019}
}

@article{khan2019novel,
    title = {A novel deep learning based framework for the detection and classification of breast cancer using transfer learning},
    author = {Khan, SanaUllah and Islam, Naveed and Jan, Zahoor and Din, Ikram Ud and Rodrigues, Joel JP C},
    journal = {Pattern Recognition Letters},
    volume = {125},
    pages = {1--6},
    year = {2019}
}

% VINet
@inproceedings{kim2019deep,
    title = {Deep Video Inpainting},
    author = {Kim, Dahun and Woo, Sanghyun and Lee, Joon-Young and Kweon, In So},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2019}
}

% TLVQM
@article{korhonen2019two,
    title = {Two-level approach for no-reference consumer video quality assessment},
    author = {Korhonen, Jari},
    journal = {IEEE Trans. Image Process.},
    volume = {28},
    number = {12},
    pages = {5923--5938},
    year = {2019}
}

% Video Flow
@article{kumar2019videoflow,
    title = {VideoFlow: A Flow-Based Generative Model for Video},
    author = {Kumar, Manoj and Babaeizadeh, Mohammad and Erhan, Dumitru and Finn, Chelsea and Levine, Sergey and Dinh, Laurent and Kingma, Durk},
    journal = {arXiv e-prints},
    eid = {arXiv:1903.01434},
    pages = {arXiv:1903.01434},
    archivePrefix = {arXiv},
    eprint = {1903.01434},
    year = {2019}
}

@inproceedings{lee2019copy,
    title = {Copy-and-Paste Networks for Deep Video Inpainting},
    author = {Lee, Sungho and Oh, Seoung Wug and Won, DaeYeun and Kim, Seon Joo},
    booktitle = {IEEE Int. Conf. Comput. Vis. (ICCV)},
    year = {2019}
}

@inproceedings{li2019quality,
    title = {Quality Assessment of In-the-Wild Videos},
    author = {Li, Dingquan and Jiang, Tingting and Jiang, Ming},
    booktitle = {Int. Conf. Multimedia (ACM-MM)},
    year = {2019}
}

% SelFlow
@inproceedings{liu2019selflow,
    title = {SelFlow: Self-Supervised Learning of Optical Flow},
    author = {Liu, Pengpeng and Lyu, Michael and King, Irwin and Xu, Jia},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2019}
}

% LLFF
@article{mildenhall2019llff,
    title = {Local Light Field Fusion: Practical View Synthesis with Prescriptive Sampling Guidelines},
    author = {Mildenhall, Ben and Srinivasan, Pratul P. and Ortiz-Cayon, Rodrigo and Kalantari, Nima Khademi and Ramamoorthi, Ravi and Ng, Ren and Kar, Abhishek},
    journal = {ACM Trans. Graph.},
    volume = {38},
    number = {4},
    year = {2019}
}

% EdgeConnect
@inproceedings{nazeri2019edgeconnect,
    title = {{EdgeConnect}: Structure Guided Image Inpainting using Edge Prediction},
    author = {Nazeri, Kamyar and Ng, Eric and Joseph, Tony and Qureshi, Faisal and Ebrahimi, Mehran},
    booktitle = {IEEE Int. Conf. Comput. Vis. (ICCV) Worksh.},
    year = {2019}
}

@misc{oculus2019asw2,
    title = {Introducing ASW 2.0: Better Accuracy, Lower Latency},
    author = {Aksoy, Volga and Beeler, Dean},
    journal = {Oculus Developer Blogs},
    howpublished = {\url{https://www.oculus.com/blog/introducing-asw-2-point-0-better-accuracy-lower-latency/}},
    note = {Accessed: 24-June-2021},
    year = {2019}
}

@inproceedings{raghu2019transfusion,
    title = {Transfusion: Understanding transfer learning for medical imaging},
    author = {Raghu, Maithra and Zhang, Chiyuan and Kleinberg, Jon and Bengio, Samy},
    booktitle = {Adv. Neural Inf. Process. Syst. (NeurIPS)},
    year = {2019}
}

% Competitive Collaboration
@inproceedings{ranjan2019competitive,
    title = {Competitive Collaboration: Joint Unsupervised Learning of Depth, Camera Motion, Optical Flow and Motion Segmentation},
    author = {Ranjan, Anurag and Jampani, Varun and Balles, Lukas and Kim, Kihwan and Sun, Deqing and Wulff, Jonas and Black, Michael J.},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2019}
}

@article{sinno2019large,
    title = {Large-Scale Study of Perceptual Video Quality},
    author = {Sinno, Zeina and Bovik, Alan C},
    journal = {IEEE Trans. Image Process.},
    volume = {28},
    number = {2},
    pages = {612--627},
    year = {2019}
}

% PBMPI / 2-step MPI
@inproceedings{srinivasan2019pushing,
    title = {Pushing the Boundaries of View Extrapolation With Multiplane Images},
    author = {Srinivasan, Pratul P. and Tucker, Richard and Barron, Jonathan T. and Ramamoorthi, Ravi and Ng, Ren and Snavely, Noah},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2019}
}

@inproceedings{unterthiner2019fvd,
    title = {{FVD} : A new Metric for Video Generation},
    author = {Unterthiner, Thomas and van Steenkiste, Sjoerd and Kurach, Karol and Marinier, Rapha\"el and Michalski, Marcin and Gelly, Sylvain},
    booktitle = {Int. Conf. Learn. Represent. (ICLR) Worksh. on Deep Generative Models for Highly Structured Data},
    year = {2019}
}

@inproceedings{villegas2019high,
    title = {High Fidelity Video Prediction with Large Stochastic Recurrent Neural Networks},
    author = {Villegas, Ruben and Pathak, Arkanath and Kannan, Harini and Erhan, Dumitru and Le, Quoc V and Lee, Honglak},
    booktitle = {Adv. Neural Inf. Process. Syst. (NeurIPS)},
    year = {2019}
}

@inproceedings{xu2019deep,
    title = {Deep Flow-Guided Video Inpainting},
    author = {Xu, Rui and Li, Xiaoxiao and Zhou, Bolei and Loy, Chen Change},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2019}
}

% Gated Convolution
@inproceedings{yu2019free,
    title = {Free-Form Image Inpainting With Gated Convolution},
    author = {Yu, Jiahui and Lin, Zhe and Yang, Jimei and Shen, Xiaohui and Lu, Xin and Huang, Thomas S.},
    booktitle = {IEEE Int. Conf. Comput. Vis. (ICCV)},
    year = {2019}
}

% 2stepQA
@article{yu2019predicting,
    title = {Predicting the Quality of Images Compressed After Distortion in Two Steps},
    author = {Yu, Xiangxu and Bampis, Christos G and Gupta, Praful and Bovik, Alan C},
    journal = {IEEE Trans. Image Process.},
    volume = {28},
    number = {12},
    pages = {5757--5770},
    year = {2019}
}

@article{choi2020deep,
    title = {Deep frame prediction for video coding},
    author = {Choi, Hyomin and Baji{\'c}, Ivan V},
    journal = {IEEE Trans. Circuits Syst. Video Technol.},
    volume = {30},
    number = {7},
    pages = {1843--1855},
    year = {2020}
}

% NSTSS
@article{dendi2020no,
    title = {No-Reference Video Quality Assessment Using Natural Spatiotemporal Scene Statistics},
    author = {Dendi, Sathya Veera Reddy and Channappayya, Sumohana S},
    journal = {IEEE Trans. Image Process.},
    volume = {29},
    pages = {5612--5624},
    year = {2020}
}

% DISTS - Simoncelli
@article{ding2020dists,
    title = {Image Quality Assessment: Unifying Structure and Texture Similarity},
    author = {K. {Ding} and K. {Ma} and S. {Wang} and E. P. {Simoncelli}},
    journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
    year = {2020}
}

@article{elharrouss2020image,
    title = {Image Inpainting: A Review},
    author = {Elharrouss, Omar and Almaadeed, Noor and Al-Maadeed, Somaya and Akbari, Younes},
    journal = {Neural Process. Lett.},
    volume = {51},
    number = {2},
    pages = {2007--2028},
    year = {2020}
}

% MemDPC
@inproceedings{han2020memory,
    title = {Memory-augmented dense predictive coding for video representation learning},
    author = {Han, Tengda and Xie, Weidi and Zisserman, Andrew},
    booktitle = {Eur. Conf. Comput. Vis. (ECCV)},
    year = {2020}
}

% LiteFlowNet2
@article{hui2020liteflownet2,
    title = {A Lightweight Optical Flow CNN - Revisiting Data Fidelity and Regularization},
    author = {Hui, Tak-Wai and Tang, Xiaoou and Loy, Chen Change},
    journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
    volume = {43},
    number = {8},
    pages = {2555-2569},
    year = {2021}
}

@article{jacob2020deep,
    title = {Do deep neural networks see the way we do?},
    author = {Jacob, Georgin and Pramod, R. T. and Katti, Harish and Arun, S. P.},
    journal = {bioRxiv},
    eid = {860759},
    year = {2020}
}

% VGPL
@article{li2020visual,
    title = {Visual Grounding of Learned Physical Models},
    author = {Li, Yunzhu and Lin, Toru and Yi, Kexin and Bear, Daniel M. and Yamins, Daniel L. K. and Wu, Jiajun and Tenenbaum, Joshua B. and Torralba, Antonio},
    journal = {arXiv e-prints},
    eid = {arXiv:2004.13664},
    pages = {arXiv:2004.13664},
    archivePrefix = {arXiv},
    eprint = {2004.13664},
    year = {2020}
}

% ARFlow
@inproceedings{liu2020arflow,
    title = {Learning by Analogy: Reliable Supervision From Transformations for Unsupervised Optical Flow Estimation},
    author = {Liu, Liang and Zhang, Jiangning and He, Ruifei and Liu, Yong and Wang, Yabiao and Tai, Ying and Luo, Donghao and Wang, Chengjie and Li, Jilin and Huang, Feiyue},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2020}
}

@article{luo2020disocclusion,
    title = {A Disocclusion Inpainting Framework for Depth-Based View Synthesis},
    author = {Luo, Guibo and Zhu, Yuesheng and Weng, Zhenyu and Li, Zhaotian},
    journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
    volume = {42},
    number = {6},
    pages = {1289-1302},
    year = {2020}
}

% NeRF
@inproceedings{mildenhall2020nerf,
    title = {NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},
    author = {Mildenhall, Ben and Srinivasan, Pratul P. and Tancik, Matthew and Barron, Jonathan T. and Ramamoorthi, Ravi and Ng, Ren},
    booktitle = {Eur. Conf. Comput. Vis. (ECCV)},
    year = {2020}
}

% VMAF code
@misc{netflix2020vmaf,
    title = {{VMAF} - Video Multi-Method Assessment Fusion},
    author = {Netflix},
    howpublished = {\url{https://github.com/Netflix/vmaf/releases/tag/v1.5.1}},
    year = {2020}
}

% RGBD-Net
@article{nguyen2020rgbd,
    title = {{RGBD-Net}: Predicting color and depth images for novel views synthesis},
    author = {Nguyen, Phong and Karnewar, Animesh and Huynh, Lam and Rahtu, Esa and Matas, Jiri and Heikkila, Janne},
    journal = {arXiv e-prints},
    eid = {arXiv:2011.14398},
    pages = {arXiv:2011.14398},
    archivePrefix = {arXiv},
    eprint = {2011.14398},
    year = {2020}
}

@article{oprea2020review,
    title = {A review on deep learning techniques for video prediction},
    author = {Oprea, Sergiu and Martinez-Gonzalez, Pablo and Garcia-Garcia, Alberto and Castro-Vargas, John Alejandro and Orts-Escolano, Sergio and Garcia-Rodriguez, Jose and Argyros, Antonis},
    journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
    year = {2020}
}

% PyTorch3D
@article{ravi2020pytorch3d,
    title = {Accelerating 3D Deep Learning with {PyTorch3D}},
    journal = {arXiv e-prints},
    eid = {arXiv:2007.08501},
    pages = {arXiv:2007.08501},
    archivePrefix = {arXiv},
    eprint = {2007.08501},
    year = {2020}
}

% 3DP
@inproceedings{shih20203dp,
    title = {3D Photography Using Context-Aware Layered Depth Inpainting},
    author = {Shih, Meng-Li and Su, Shih-Yang and Kopf, Johannes and Huang, Jia-Bin},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2020}
}

% PreCNet
@article{straka2020precnet,
    title = {{PreCNet}: Next Frame Video Prediction Based on Predictive Coding},
    author = {Straka, Zdenek and Svoboda, Tomas and Hoffmann, Matej},
    journal = {arXiv e-prints},
    eid = {arXiv:2004.14878},
    pages = {arXiv:2004.14878},
    archivePrefix = {arXiv},
    eprint = {2004.14878},
    year = {2020}
}

% RAFT
@inproceedings{teed2020raft,
    title = {{RAFT}: Recurrent All-Pairs Field Transforms for Optical Flow},
    author = {Teed, Zachary and Deng, Jia},
    booktitle = {Eur. Conf. Comput. Vis. (ECCV)},
    year = {2020}
}

% Single image MPI
@inproceedings{tucker2020single,
    title = {Single-View View Synthesis With Multiplane Images},
    author = {Tucker, Richard and Snavely, Noah},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2020}
}

@inproceedings{weissenborn2020Scaling,
    title = {Scaling Autoregressive Video Models},
    author = {Weissenborn, Dirk and T{\"a}ckstr{\"o}m, Oscar and Uszkoreit, Jakob},
    booktitle = {Int. Conf. Learn. Represent. (ICLR)},
    year = {2020}
}

% SynSin
@inproceedings{wiles2020synsin,
    title = {SynSin: End-to-End View Synthesis From a Single Image},
    author = {Wiles, Olivia and Gkioxari, Georgia and Szeliski, Richard and Johnson, Justin},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2020}
}

@inproceedings{wu2020future,
    title = {Future Video Synthesis With Object Motion Prediction},
    author = {Wu, Yue and Gao, Rongrong and Park, Jaesik and Chen, Qifeng},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2020}
}

@inproceedings{yoon2020novel,
    title = {Novel View Synthesis of Dynamic Scenes With Globally Coherent Depths From a Monocular Camera},
    author = {Yoon, Jae Shin and Kim, Kihwan and Gallo, Orazio and Park, Hyun Soo and Kautz, Jan},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2020}
}

% Blendswap
@misc{blendswap2021blendswap,
    title = {Blend Swap},
    howpublished = {\url{https://www.blendswap.com}},
    note = {Accessed: 07-Nov-2021}
}

@article{chen2021mvsnerf,
    title = {{MVSNeRF}: Fast Generalizable Radiance Field Reconstruction from Multi-View Stereo},
    author = {Chen, Anpei and Xu, Zexiang and Zhao, Fuqiang and Zhang, Xiaoshuai and Xiang, Fanbo and Yu, Jingyi and Su, Hao},
    journal = {arXiv e-prints},
    eid = {arXiv:2103.15595},
    pages = {arXiv:2103.15595},
    archivePrefix = {arXiv},
    eprint = {2103.15595},
    year = {2021}
}

% Dynamic View Synthesis
@article{gao2021dynamic,
    title = {Dynamic View Synthesis from Dynamic Monocular Video},
    author = {Gao, Chen and Saraf, Ayush and Kopf, Johannes and Huang, Jia-Bin},
    journal = {arXiv e-prints},
    eid = {arXiv:2105.06468},
    pages = {arXiv:2105.06468},
    archivePrefix = {arXiv},
    eprint = {2105.06468},
    year = {2021}
}

% GeoNeRF
@article{johari2021geonerf,
    title = {{GeoNeRF}: Generalizing NeRF with Geometry Priors},
    author = {Mahdi Johari, Mohammad and Lepoittevin, Yann and Fleuret, Fran{\c{c}}ois},
    journal = {arXiv e-prints},
    eid = {arXiv:2111.13539},
    pages = {arXiv:2111.13539},
    archivePrefix = {arXiv},
    eprint = {2111.13539},
    year = {2021}
}

% MINE
@inproceedings{li2021mine,
    title = {{MINE}: Towards Continuous Depth MPI With NeRF for Novel View Synthesis},
    author = {Li, Jiaxin and Feng, Zijian and She, Qi and Ding, Henghui and Wang, Changhu and Lee, Gim Hee},
    booktitle = {IEEE Int. Conf. Comput. Vis. (ICCV)},
    year = {2021}
}

@inproceedings{lin2021deep,
    title = {Deep 3D Mask Volume for View Synthesis of Dynamic Scenes},
    author = {Lin, Kai-En and Xiao, Lei and Liu, Feng and Yang, Guowei and Ramamoorthi, Ravi},
    booktitle = {IEEE Int. Conf. Comput. Vis. (ICCV)},
    year = {2021}
}

@inproceedings{liu2021deep,
    title = {Deep Learning in Latent Space for Video Prediction and Compression},
    author = {Liu, Bowen and Chen, Yu and Liu, Shiyu and Kim, Hun-Seok},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2021}
}

@article{rochow2021fadiv,
    title = {{FaDIV-Syn}: Fast Depth-Independent View Synthesis},
    author = {Rochow, Andre and Schwarz, Max and Weinmann, Michael and Behnke, Sven},
    journal = {arXiv e-prints},
    eid = {arXiv:2106.13139},
    pages = {arXiv:2106.13139},
    archivePrefix = {arXiv},
    eprint = {2106.13139},
    year = {2021}
}

@inproceedings{sarkar2021decomposing,
    title = {Decomposing camera and object motion for an improved video sequence prediction},
    author = {Sarkar, Meenakshi and Ghose, Debasish and Bala, Aniruddha},
    booktitle = {Adv. Neural Inf. Process. Syst. (NeurIPS) Worksh. on Pre-registration in Machine Learning},
    year = {2021}
}

% PVQA
@article{somraj2021pvqa,
    title = {Understanding the Perceived Quality of Video Predictions},
    author = {Somraj, Nagabhushan and Kashi, Manoj Surya and Arun, S. P. and Soundararajan, Rajiv},
    journal = {arXiv e-prints},
    eid = {arXiv:2005.00356},
    pages = {arXiv:2005.00356},
    archivePrefix = {arXiv},
    eprint = {2005.00356},
    year = {2021}
}

@article{suhail2021light,
    title = {Light Field Neural Rendering},
    author = {Suhail, Mohammed and Esteves, Carlos and Sigal, Leonid and Makadia, Ameesh},
    journal = {arXiv e-prints},
    eid = {arXiv:2112.09687},
    pages = {arXiv:2112.09687},
    archivePrefix = {arXiv},
    eprint = {2112.09687},
    year = {2021}
}

% AutoFlow
@inproceedings{sun2021autoflow,
    title = {{AutoFlow}: Learning a Better Training Set for Optical Flow},
    author = {Sun, Deqing and Vlasic, Daniel and Herrmann, Charles and Jampani, Varun and Krainin, Michael and Chang, Huiwen and Zabih, Ramin and Freeman, William T. and Liu, Ce},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2021}
}

% Turbosquid
@misc{turbosquid2021turbosquid,
    title = {TurboSquid},
    howpublished = {\url{https://www.turbosquid.com/}},
    note = {Accessed: 07-Nov-2021}
}

% IBRNet
@inproceedings{wang2021ibrnet,
    title = {{IBRNet}: Learning Multi-View Image-Based Rendering},
    author = {Wang, Qianqian and Wang, Zhicheng and Genova, Kyle and Srinivasan, Pratul P. and Zhou, Howard and Barron, Jonathan T. and Martin-Brualla, Ricardo and Snavely, Noah and Funkhouser, Thomas},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2021}
}

% NeX
@inproceedings{wizadwongsa2021nex,
    title = {{NeX}: Real-Time View Synthesis With Neural Basis Expansion},
    author = {Wizadwongsa, Suttisak and Phongthawee, Pakkapon and Yenphraphai, Jiraphon and Suwajanakorn, Supasorn},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2021}
}

% pixel NeRF
@inproceedings{yu2021pixelnerf,
    title = {{pixelNeRF}: Neural Radiance Fields From One or Few Images},
    author = {Yu, Alex and Ye, Vickie and Tancik, Matthew and Kanazawa, Angjoo},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)},
    year = {2021}
}

% IVP
@inproceedings{kanchana2022ivp,
    title = {Revealing Disocclusions in Temporal View Synthesis through Infilling Vector Prediction},
    author = {Kanchana, Vijayalakshmi and Somraj, Nagabhushan and Yadwad, Suraj and Soundararajan, Rajiv},
    booktitle = {IEEE Winter Conf. App. Comput. Vis. (WACV)},
    year = {2022}
}